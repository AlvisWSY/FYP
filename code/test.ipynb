{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data.dataset import random_split\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from itertools import cycle\n",
    "import torchvision.models as models\n",
    "colors = cycle(\"bgrcmykbgrcmykbgrcmykbgrcmyk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "#set the seed for random environment\n",
    "#here we set the seed to 42\n",
    "#########################################################################################\n",
    "def seed_everything(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "#when import the module the seed is set\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveFormDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        root_dir: 数据集的根目录\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "\n",
    "        # 自动发现数据和标签\n",
    "        for label in ['noise', 'internal', 'corona']:\n",
    "            data_dir = os.path.join(root_dir, label)\n",
    "            for file in os.listdir(data_dir):\n",
    "                file_path = os.path.join(data_dir, file)\n",
    "                if file.endswith('.csv'):\n",
    "                    # 读取CSV文件，跳过表头\n",
    "                    data = pd.read_csv(file_path, header=None, skiprows=1, sep='[,\\t]', engine='python').values\n",
    "                    # 对于文件中的每一行，保存为一个独立的样本\n",
    "                    for row in data:\n",
    "                        self.samples.append(row.astype(np.float32))\n",
    "                        self.labels.append(label)\n",
    "        \n",
    "        # 将文本标签转换为整数\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 返回单个样本和标签\n",
    "        sample = self.samples[idx]\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return sample, label\n",
    "\n",
    "# 使用示例\n",
    "root_dir = '/media/mldadmin/home/s123mdg34_04/WangShengyuan/FYP/dataset' # 根据实际路径调整\n",
    "WaveForm = WaveFormDataset(root_dir=root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 dataset 是你的完整数据集\n",
    "dataset_size = len(WaveForm)\n",
    "train_size = int(dataset_size * 0.7) # 70% 数据用于训练\n",
    "val_size = int(dataset_size * 0.15) # 15% 数据用于验证\n",
    "test_size = dataset_size - train_size - val_size # 剩下的 15% 数据用于测试\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(WaveForm, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -0.4100,  -0.5400,  -0.8200,  -0.6800,  -0.5400,  -0.4100,  -0.9500,\n",
       "         -0.2700,  -0.1400,  -0.5400,  -0.4100,  -0.5400,  -0.6800,  -0.9500,\n",
       "         -0.5400,  -0.6800,  -0.5400,  -0.5400,  -0.5400,  -0.6800,  -0.5400,\n",
       "         -0.8200,  -0.2700,  -0.5400,  -1.0900,  -0.8200,  -0.5400,  -0.8200,\n",
       "         -0.6800,  -0.5400,  -0.6800,  -1.5000, -12.2400,  -7.6200,  -3.9400,\n",
       "         -4.0800,  -1.9000,  -1.5000,  -0.8200,  -0.2700,   0.4100,   0.8200,\n",
       "          1.7700,   0.1400,   0.8200,   0.5400,   1.3600,   0.9500,   1.2200,\n",
       "          1.0900,   0.6800,   0.9500,   0.2700,   0.5400,   0.5400,   0.1400,\n",
       "          0.5400,   0.1400,   0.2700,   0.2700,  -0.4100,  -0.2700,  -0.2700,\n",
       "          0.0000,  -0.1400,  -0.2700,  -0.4100,  -0.5400,  -0.6800,  -0.5400,\n",
       "         -0.6800,  -0.2700,  -0.4100,  -0.6800,  -0.6800,  -0.5400,  -0.4100,\n",
       "         -0.6800,  -0.8200,  -0.6800,  -0.5400,  -0.2700,  -0.5400,  -0.5400,\n",
       "         -0.5400,  -1.3600,  -0.9500,  -0.6800,  -0.8200,  -0.9500,  -0.8200,\n",
       "         -0.6800,  -0.2700,  -0.4100,  -0.8200,  -0.6800,  -0.5400,  -0.6800,\n",
       "         -0.5400,  -1.2200,  -0.6800,  -0.8200,  -0.9500,  -0.5400,  -0.6800,\n",
       "         -0.6800,  -0.8200,  -0.9500,  -0.8200,  -0.4100,  -0.9500,  -0.8200,\n",
       "         -0.8200,  -0.6800,  -0.4100,  -0.8200,  -1.0900,  -0.4100,  -0.4100,\n",
       "         -0.9500,  -0.6800,  -0.4100,  -0.9500,  -1.2200,  -0.5400,  -0.9500,\n",
       "         -0.6800,  -0.6800,  -0.6800,  -0.8200,  -0.5400,  -0.2700,  -0.6800,\n",
       "         -0.5400,  -0.6800,  -0.2700,  -1.0900,  -1.2200,  -0.4100,  -0.8200,\n",
       "         -0.4100,  -0.9500,  -0.6800,  -0.5400,  -0.5400,  -0.8200,  -0.6800,\n",
       "         -0.5400,  -0.5400,  -0.8200,  -0.8200,  -0.9500,  -0.1400,  -0.4100,\n",
       "         -0.8200,  -0.8200,  -0.5400,  -0.6800,  -0.9500,  -0.4100,  -1.3600,\n",
       "         -0.6800,  -0.8200,  -0.8200,  -0.5400,  -1.2200,  -0.6800,  -0.6800,\n",
       "         -0.5400,  -0.8200,  -0.4100,  -0.8200,  -0.4100,  -0.9500,  -0.6800,\n",
       "         -0.6800,  -0.2700,  -0.8200,  -0.4100,  -0.8200,  -0.9500,  -0.5400,\n",
       "         -0.4100,  -0.5400,  -0.8200,  -1.0900,  -0.2700,  -0.5400,  -1.2200,\n",
       "         -0.5400,  -0.5400,  -0.2700,  -0.4100,  -0.5400,  -0.8200,  -0.4100,\n",
       "         -0.6800,  -0.4100,  -0.6800,  -0.6800,  -0.6800,  -0.8200,  -0.8200,\n",
       "         -0.6800,  -0.6800,  -0.8200,  -0.9500,  -1.0900,  -0.8200,  -0.4100,\n",
       "         -0.5400,  -0.6800,  -0.8200,  -0.8200,  -0.8200,  -0.4100,  -0.9500,\n",
       "         -0.5400,  -0.5400,  -0.9500,  -0.4100,  -0.8200,  -0.6800,  -0.6800,\n",
       "         -0.8200,  -0.5400,  -0.5400,  -0.5400,  -0.6800,  -0.8200,  -0.9500,\n",
       "         -0.8200,  -0.5400,  -1.0900,  -1.2200,  -0.6800,  -0.2700,  -0.4100,\n",
       "         -0.5400,  -0.8200,  -1.2200,  -0.9500,  -0.6800,  -0.9500,  -0.8200,\n",
       "         -0.9500,  -0.5400,  -0.9500,  -0.8200,  -0.8200,  -0.8200,  -0.6800,\n",
       "         -0.9500,  -0.4100,  -0.6800,  -0.9500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, label = train_loader.dataset[0]\n",
    "sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FCN model\n",
    "class FourLayerFCN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FourLayerFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # 添加dropout层，dropout率为0.5\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # 在激活函数后添加dropout\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)  # 在激活函数后添加dropout\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)  # 在激活函数后添加dropout\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input size, hidden size, and number of classes\n",
    "input_size = len(train_loader.dataset[0][0])\n",
    "hidden_size = 128\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an instance of the FourLayerFCN model\n",
    "model = FourLayerFCN(input_size, hidden_size, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]          32,896\n",
      "              ReLU-2                  [-1, 128]               0\n",
      "           Dropout-3                  [-1, 128]               0\n",
      "            Linear-4                  [-1, 128]          16,512\n",
      "              ReLU-5                  [-1, 128]               0\n",
      "           Dropout-6                  [-1, 128]               0\n",
      "            Linear-7                  [-1, 128]          16,512\n",
      "              ReLU-8                  [-1, 128]               0\n",
      "           Dropout-9                  [-1, 128]               0\n",
      "           Linear-10                    [-1, 3]             387\n",
      "================================================================\n",
      "Total params: 66,307\n",
      "Trainable params: 66,307\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 0.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "summary(model, (input_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def FCNtrain(model, train_loader, val_loader, num_epochs, criterion, optimizer):\n",
    "    # Training loop\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, (samples, labels) in enumerate(train_loader):\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(samples)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Statistics\n",
    "            total_loss += loss.item()\n",
    "            total_samples += labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "        train_loss = total_loss / total_samples\n",
    "        train_losses.append(train_loss)\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            total_samples = 0\n",
    "            total_correct = 0\n",
    "            for i, (samples, labels) in enumerate(val_loader):\n",
    "                samples = samples.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # Forward pass\n",
    "                outputs = model(samples)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "                # Statistics\n",
    "                total_loss += loss.item()\n",
    "                total_samples += labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "            val_loss = total_loss / total_samples\n",
    "            val_losses.append(val_loss)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}')\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, f'/media/mldadmin/home/s123mdg34_04/WangShengyuan/FYP/checkpoint/FCN/checkpoint_{epoch}.pth')\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.0006, Val Loss: 0.0001\n",
      "Epoch [2/10], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [3/10], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Epoch [4/10], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [5/10], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [6/10], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [7/10], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [8/10], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [9/10], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [10/10], Train Loss: 0.0001, Val Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = (FCNtrain(model, train_loader, val_loader, num_epochs, criterion, optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECKPOINT: \n",
    "    checkpoint = torch.load('checkpoint.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_samples = 0\n",
    "total_correct = 0\n",
    "with torch.no_grad():\n",
    "    for samples, labels in test_loader:\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(samples)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = total_correct / total_samples\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mldadmin/home/s123mdg34_04/anaconda3/envs/FYP/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/media/mldadmin/home/s123mdg34_04/anaconda3/envs/FYP/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define the ResNet model\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.conv1 = nn.Conv1d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "summary(resnet, (1, input_size))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = train(resnet, train_loader, val_loader, num_epochs, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 3D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print the model architecture\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(resnet)\n\u001b[0;32m----> 3\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/torchvision/models/resnet.py:269\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m--> 269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:138\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:416\u001b[0m, in \u001b[0;36mBatchNorm2d._check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m--> 416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 4D input (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: expected 4D input (got 3D input)"
     ]
    }
   ],
   "source": [
    "# Print the model architecture\n",
    "print(resnet)\n",
    "summary(resnet, (1, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = train(model, train_loader, val_loader, num_epochs, criterion, optimizer)\n",
    "\n",
    "# Plot the training and validation losses\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "total_samples = 0\n",
    "total_correct = 0\n",
    "with torch.no_grad():\n",
    "    for samples, labels in test_loader:\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(samples)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = total_correct / total_samples\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for samples, labels in train_loader:\n",
    "    samples = samples.numpy()\n",
    "    labels = labels.numpy()\n",
    "    X_train.extend(samples)\n",
    "    y_train.extend(labels)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "for samples, labels in val_loader:\n",
    "    samples = samples.numpy()\n",
    "    labels = labels.numpy()\n",
    "    X_val.extend(samples)\n",
    "    y_val.extend(labels)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for samples, labels in test_loader:\n",
    "    samples = samples.numpy()\n",
    "    labels = labels.numpy()\n",
    "    X_test.extend(samples)\n",
    "    y_test.extend(labels)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the SVM model\n",
    "model = svm.SVC(kernel='rbf', C=1, gamma='auto')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = np.mean(y_val_pred == y_val)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = np.mean(y_test_pred == y_test)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "plt.imshow(conf_matrix, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the ROC curve\n",
    "n_classes = 3\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y_test = y_test.astype(int)\n",
    "y_test_pred = y_test_pred.astype(int)\n",
    "y_test_one_hot = np.eye(n_classes)[y_test]\n",
    "y_test_pred_one_hot = np.eye(n_classes)[y_test_pred]\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_one_hot[:, i], y_test_pred_one_hot[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve of class {i} (area = {roc_auc[i]:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
